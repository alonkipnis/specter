{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "1. Create DocEmbSim module to get similarity based on a pre-trained SPECTER model file\n",
    "2. Think about a better way to represent nagative examples\n",
    "3. Design a feedback mechanisim -- the result of this feedback is translated to some 'connection weight' to an applicaiton-pair. \n",
    "\n",
    "### Note: current connection weight sacle:\n",
    "    1. Non-related ('negative connection')\n",
    "    4. Destination application is rejected because target\n",
    "    5. Target application is rejected because destination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'import_submodules' from 'allennlp.common.util' (/usr/local/lib/python3.8/site-packages/allennlp/common/util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-75cfee082c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchival\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimport_submodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'specter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'import_submodules' from 'allennlp.common.util' (/usr/local/lib/python3.8/site-packages/allennlp/common/util.py)"
     ]
    }
   ],
   "source": [
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.common.util import import_submodules\n",
    "\n",
    "import_submodules('specter')\n",
    "\n",
    "archive_file = \"../model.tar.gz\"\n",
    "cuda_device = -1\n",
    "\n",
    "metadata = '../data/my_training/test.txt'\n",
    "included_text_fields = 'abstract title'\n",
    "vocab_dir = './data/vocab/'\n",
    "\n",
    "\n",
    "overrides = f\"{{'model':{{'predict_mode':'true','include_venue':'false'}},\\\n",
    "                'dataset_reader' : {{ 'type':'specter_data_reader','predict_mode':'true',\\\n",
    "                                     'paper_features_path':'{metadata}',\\\n",
    "                                     'included_text_fields': '{included_text_fields}'}},\\\n",
    "                                      'vocabulary' : {{'directory_path':'{vocab_dir}'}}\\\n",
    "                }}\"\n",
    "\n",
    "archive = load_archive(archive_file, cuda_device = cuda_device)\n",
    "                      \n",
    "Predictor.from_archive(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.5.1 available.\n",
      "INFO:transformers.file_utils:TensorFlow version 2.2.0 available.\n",
      "INFO:allennlp.models.archival:loading archive file ../model.tar.gz\n",
      "INFO:allennlp.models.archival:extracting archive file ../model.tar.gz to temp dir /var/folders/3n/c1thdb3136qc3c_4t5br9r6c0000gq/T/tmptxr2up5x\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "specter is not a registered name for Model. You probably need to use the --include-package flag to load your custom code. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ebe17c0bc051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../model.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{word}\\t{tag}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         return Predictor.from_archive(\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mload_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mpredictor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mdataset_reader_to_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_reader_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/allennlp/models/archival.py\u001b[0m in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, opt_level, overrides, weights_file)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Instantiate model. Use a duplicate of the config, as it will get consumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     model = Model.load(\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mweights_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# This allows subclasses of Model to override _load.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmodel_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# If you're using from_archive to specify your model (e.g., for fine tuning), then you\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36mby_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"instantiating registered subclass {name} of {cls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36mresolve_class_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# is not a qualified class name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             raise ConfigurationError(\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;34mf\"{name} is not a registered name for {cls.__name__}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;34m\"You probably need to use the --include-package flag \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: specter is not a registered name for Model. You probably need to use the --include-package flag to load your custom code. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly."
     ]
    }
   ],
   "source": [
    "from allennlp.predictors import Predictor\n",
    "predictor = Predictor.from_path(\"../model.tar.gz\")\n",
    "results = predictor.predict(sentence=\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?\")\n",
    "for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "    print(f\"{word}\\t{tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class trained_model(object) :\n",
    "    \"\"\"\n",
    "        Load trained SPECTER model for embedding.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "        model_file       path to the file containing the trained model\n",
    "    \"\"\"\n",
    "    def __init__(model_file) :\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '../model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def embed(ids, model, metadata, output_file, cuda_device=0, batch_size=1, vocab_dir='data/vocab',\n",
    "          included_text_fields = 'abstract title', weights_file=None\n",
    "          ):\n",
    "    \n",
    "    overrides = f\"{{'model':{{'predict_mode':'true','include_venue':'false'}},'dataset_reader':{{'type':'specter_data_reader','predict_mode':'true','paper_features_path':'{metadata}','included_text_fields': '{included_text_fields}'}},'vocabulary':{{'directory_path':'{vocab_dir}'}}}}\"\n",
    "\n",
    "    command = [\n",
    "        'python3',\n",
    "        'specter/predict_command.py',\n",
    "        'predict',\n",
    "        model,\n",
    "        ids,\n",
    "        '--include-package',\n",
    "        'specter',\n",
    "        '--predictor',\n",
    "        'specter_predictor',\n",
    "        '--overrides',\n",
    "        f'\"{overrides}\"',\n",
    "        '--cuda-device',\n",
    "        str(cuda_device),\n",
    "        '--output-file',\n",
    "        output_file,\n",
    "        '--batch-size',\n",
    "        str(batch_size),\n",
    "        '--silent'\n",
    "    ]\n",
    "    if weights_file is not None:\n",
    "        command.extend(['--weights-file', args.weights_file])\n",
    "    \n",
    "    logging.info('running command:')\n",
    "    logging.info(' '.join(command))\n",
    "    subprocess.run(' '.join(command), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:running command:\n",
      "INFO:root:python3 specter/predict_command.py predict ./model.tar.gz ./data/my_training/test.txt --include-package specter --predictor specter_predictor --overrides \"{'model':{'predict_mode':'true','include_venue':'false'},'dataset_reader':{'type':'specter_data_reader','predict_mode':'true','paper_features_path':'./data/my_training/metadata.json','included_text_fields': 'abstract title'},'vocabulary':{'directory_path':'./data/vocab'}}\" --cuda-device -1 --output-file ./output.jsonl --batch-size 16 --silent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "embed(ids = './data/my_training/test.txt', metadata='./data/my_training/metadata.json',\n",
    "      model='./model.tar.gz', output_file = './output.jsonl', vocab_dir='./data/vocab', batch_size=16,\n",
    "      cuda_device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE            \u001b[34mdist\u001b[m\u001b[m               \u001b[34mmodel-output\u001b[m\u001b[m       \u001b[34mspecter\u001b[m\u001b[m\r\n",
      "README.md          \u001b[34menv\u001b[m\u001b[m                model.tar.gz       \u001b[34mspecter.egg-info\u001b[m\u001b[m\r\n",
      "archive.tar.gz     \u001b[34mexperiment_configs\u001b[m\u001b[m requirements.txt   train.sh\r\n",
      "\u001b[34mbuild\u001b[m\u001b[m              files.sh           \u001b[34mscripts\u001b[m\u001b[m\r\n",
      "\u001b[34mdata\u001b[m\u001b[m               init.sh            setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kipnisal/specter/scripts\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
